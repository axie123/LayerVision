{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision as tvn\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as skm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_params = {'nodes_layer_0': 1024,        \n",
    "             'nodes_layer_1': 512,  \n",
    "             'nodes_layer_2': 256,\n",
    "             'nodes_layer_3': 128\n",
    "             }\n",
    "\n",
    "prop_params = {'ReLU_1': 0.2,               \n",
    "               'ReLU_2': 0.2,\n",
    "               'ReLU_3': 0.2,\n",
    "               'ReLU_4': 0.2,\n",
    "               'Drop_1': 0.25,\n",
    "               'Drop_2': 0.25,\n",
    "               'Drop_3': 0.25,\n",
    "               'Drop_4': 0.25\n",
    "               }\n",
    "\n",
    "training_conditions = {'n_epochs': 1,                  \n",
    "                       'batch_size_train': 64,\n",
    "                       'batch_size_test': 1000,\n",
    "                       'learning_rate': 0.01,\n",
    "                       'momentum': 0.05,\n",
    "                       'log_interval': 10,\n",
    "                       'rdm_seed': 1\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x230c5facbd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(training_conditions['rdm_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(tvn.datasets.MNIST('/files/', train = True, download = True,\n",
    "                                                            transform = tvn.transforms.Compose([tvn.transforms.ToTensor(),\n",
    "                                                            tvn.transforms.Normalize((0.1307,), (0.3081,))])),batch_size=training_conditions['batch_size_train'], shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(tvn.datasets.MNIST('/files/', train = False, download = True,\n",
    "                                                            transform = tvn.transforms.Compose([tvn.transforms.ToTensor(),\n",
    "                                                            tvn.transforms.Normalize((0.1307,), (0.3081,))])),batch_size=training_conditions['batch_size_test'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    def __init__(self,nn_params, prop_params):\n",
    "        super(NN, self).__init__()\n",
    "        initial_features = 784\n",
    "        final_features = 10\n",
    "        self.hidden_layerin = torch.nn.Sequential(torch.nn.Linear(initial_features,nn_params['nodes_layer_0']),torch.nn.LeakyReLU(prop_params['ReLU_1']),torch.nn.Dropout(prop_params['Drop_1']))\n",
    "        self.hidden_layer1 = torch.nn.Sequential(torch.nn.Linear(nn_params['nodes_layer_0'],nn_params['nodes_layer_1']),torch.nn.LeakyReLU(prop_params['ReLU_2']),torch.nn.Dropout(prop_params['Drop_2']))\n",
    "        self.hidden_layer2 = torch.nn.Sequential(torch.nn.Linear(nn_params['nodes_layer_1'],nn_params['nodes_layer_2']),torch.nn.LeakyReLU(prop_params['ReLU_3']),torch.nn.Dropout(prop_params['Drop_3']))\n",
    "        self.hidden_layer3 = torch.nn.Sequential(torch.nn.Linear(nn_params['nodes_layer_2'],nn_params['nodes_layer_3']),torch.nn.LeakyReLU(prop_params['ReLU_4']),torch.nn.Dropout(prop_params['Drop_4']))\n",
    "        self.layer_out = torch.nn.Linear(nn_params['nodes_layer_3'],final_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,784)\n",
    "        x_in = self.hidden_layerin(x)\n",
    "        x_1 = self.hidden_layer1(x_in)\n",
    "        x_2 = self.hidden_layer2(x_1)\n",
    "        x_3 = self.hidden_layer3(x_2)\n",
    "        x_4 = self.layer_out(x_3)\n",
    "        x_out = torch.nn.functional.log_softmax(x_4,dim=1)\n",
    "        return [x_out,x_in,x_1,x_2,x_3]\n",
    "\n",
    "network = NN(nn_params, prop_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(network.parameters(), lr= training_conditions['learning_rate'],momentum= training_conditions['momentum'])\n",
    "loss_function = torch.nn.functional.nll_loss\n",
    "\n",
    "def train(network,train_set,loss_func,method,log_interval,epochs):\n",
    "    try:\n",
    "        network.train()\n",
    "        for index, (data, truth) in enumerate(train_set):\n",
    "            method.zero_grad()\n",
    "            output = network(data) \n",
    "            loss = loss_func(output[0], truth)\n",
    "            loss.backward()\n",
    "            method.step()\n",
    "            if index % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epochs, index * len(data), len(train_set.dataset),\n",
    "                                                                    100. * index / len(train_set), loss.item()))\n",
    "        return [output,truth]\n",
    "    except:\n",
    "        print('Error occurred during training. Please check errors: ', sys.exc_info()[2])\n",
    "\n",
    "\n",
    "def test(network,test_set,loss_func):\n",
    "    try:\n",
    "        test_losses = []\n",
    "        network.eval()\n",
    "        total_test_loss = 0\n",
    "        total_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for index, (data, truth) in enumerate(test_set):\n",
    "                output = network(data)\n",
    "                test_loss = loss_func(output[0], truth, size_average = False)\n",
    "                total_test_loss += test_loss.item()\n",
    "                pred = output[0].data.max(1, keepdim = True)[1]\n",
    "                total_correct += pred.eq(truth.data.view_as(pred)).sum()\n",
    "        avg_test_loss = total_test_loss / len(test_set.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(avg_test_loss, total_correct, len(test_set.dataset),\n",
    "            100. * total_correct / len(test_set.dataset)))\n",
    "        return [output, truth]\n",
    "    except:\n",
    "        print('Error occurred during testing. Please check error: ', sys.exc_info()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy Xie\\Anaconda3\\envs\\api-dev\\lib\\site-packages\\torch\\nn\\_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3011, Accuracy: 1095/10000 (10%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.294295\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.301305\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.297035\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.297702\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.290997\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.290269\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.292796\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.308970\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.294259\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.270344\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.271259\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.279764\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.281452\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.277405\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.278854\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.269268\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.277972\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.280428\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.268578\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.268985\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.251978\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.253022\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.258549\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.240758\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.237310\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.237474\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.241807\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.215782\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.225364\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.192402\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.190834\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.209949\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.161926\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.176045\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.149569\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.125822\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.136168\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 2.119009\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.064044\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.071490\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.065675\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.052538\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 1.929598\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 1.985813\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 1.913090\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 1.919617\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 1.745286\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 1.818349\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 1.769043\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 1.548797\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.572551\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 1.506849\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 1.499697\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 1.209310\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 1.323237\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 1.486742\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 1.348274\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 1.121129\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 1.138653\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 1.176858\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.030933\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 1.046401\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.927151\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 1.033747\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 1.023222\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.909902\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 1.061411\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.987432\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.982405\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.858212\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.797097\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.919493\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.860956\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.810844\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.859947\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.721122\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 1.037444\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.627919\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.594458\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.747946\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.866728\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.614801\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.737064\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.853031\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.583857\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.766320\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.811464\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.673823\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.822294\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.655250\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.728312\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.528939\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.684269\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.496996\n",
      "\n",
      "Test set: Avg. loss: 0.5129, Accuracy: 8555/10000 (85%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(training_conditions['n_epochs'] + 1)]\n",
    "\n",
    "test(network,test_loader,loss_function)\n",
    "for epoch in range(1, training_conditions['n_epochs'] + 1): \n",
    "    training_data_results = train(network,train_loader,loss_function,optimizer,training_conditions['log_interval'],1)\n",
    "    testing_data_results = test(network,test_loader,loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_visuals(layer_num,data_results,ith):\n",
    "    chosen_layer = data_results[0][layer_num]\n",
    "    while True:\n",
    "        print('The dimensions of the layer: ' + str(chosen_layer.shape))\n",
    "        base = input('Base: ')\n",
    "        if base == 'exit':\n",
    "            break\n",
    "        height = input('Height: ')\n",
    "        try:\n",
    "            fig = plt.figure(figsize=(int(base),int(height)))\n",
    "            for i in range(ith,ith+10):\n",
    "                image = chosen_layer[i].view(int(height),int(base))\n",
    "                for j in range(10):\n",
    "                    plt.subplot(4,5,j + 1)\n",
    "                    plt.tight_layout()\n",
    "                    plt.title(j + ith, fontsize = 25)\n",
    "                    plt.imshow(image.detach(), cmap = 'gray', interpolation = 'none')\n",
    "                    plt.xticks([])\n",
    "                    plt.yticks([])\n",
    "            plt.show()\n",
    "            break\n",
    "        except (RuntimeError):\n",
    "            print('The proposed dimensions do not match that of the output.\\n')\n",
    "        except (ValueError):\n",
    "            print('Please use integers only.\\n')\n",
    "        except:\n",
    "            print('Unexpected Error: ' + sys.exc_info()[2] + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the layer: torch.Size([32, 512])\n",
      "Base: 32\n",
      "Height: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy Xie\\Anaconda3\\envs\\api-dev\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2304x1152 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer_visuals(2,training_data_results,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_loss_analysis(layer_num,data_results,loss_func):\n",
    "    chosen_layer = data_results[0][layer_num]\n",
    "    print('The dimensions of the layer: ' + str(chosen_layer.shape) +'\\n')\n",
    "    try:\n",
    "        if len(chosen_layer.shape) == 2:\n",
    "            layer = torch.nn.functional.log_softmax(chosen_layer, dim=1)\n",
    "            loss = loss_func(layer, data_results[1])\n",
    "            print('Layer Number: {}, Loss: {:.6f}\\n'.format(layer_num, loss)) \n",
    "        else:\n",
    "            print('Invalid')\n",
    "    except:\n",
    "        print('There is a problem with the information you entered: ' + sys.exc_info()[2] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the layer: torch.Size([32, 512])\n",
      "\n",
      "Layer Number: 2, Loss: 6.762490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layer_loss_analysis(2,training_data_results,loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "def accuracy_individual_classes(network,classes,test_set):\n",
    "    try:\n",
    "        class_correct = list(0. for i in range(len(classes)))\n",
    "        class_total = list(0. for i in range(len(classes)))\n",
    "        for data in test_set:\n",
    "            images, labels = data\n",
    "            outputs = network(images)\n",
    "            _, predicted = torch.max(outputs[0], 1)\n",
    "            correct = (predicted == labels).squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += correct[i].item()\n",
    "                class_total[label] += 1\n",
    "        for i in range(len(classes)):\n",
    "            print('Accuracy of %s : %2d%%  [%i/%i]' % (classes[i], 100 * class_correct[i] / class_total[i], class_correct[i], class_total[i]))\n",
    "    except:\n",
    "        print('There is an error: ' + sys.exc_info()[2] + '\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0 : 96%  [949/980]\n",
      "Accuracy of 1 : 97%  [1105/1135]\n",
      "Accuracy of 2 : 78%  [812/1032]\n",
      "Accuracy of 3 : 84%  [850/1010]\n",
      "Accuracy of 4 : 85%  [844/982]\n",
      "Accuracy of 5 : 70%  [631/892]\n",
      "Accuracy of 6 : 92%  [889/958]\n",
      "Accuracy of 7 : 88%  [908/1028]\n",
      "Accuracy of 8 : 79%  [779/974]\n",
      "Accuracy of 9 : 78%  [788/1009]\n"
     ]
    }
   ],
   "source": [
    "accuracy_individual_classes(network,classes,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_textfile(file,pandas_true,directory):\n",
    "    try:\n",
    "        if pandas_true == False:\n",
    "            f = open(directory,'w+')\n",
    "            for line in file:\n",
    "                f.writelines(str(list(line.numpy())))\n",
    "            f.close()\n",
    "        else:\n",
    "            file.to_csv(directory,'w+')\n",
    "    except:\n",
    "        print('There is an error: ' + sys.exc_info()[2] + '\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_biases(network):\n",
    "    parameters = {}\n",
    "    for i in network.named_parameters():\n",
    "        parameters[i[0]] = i[1] \n",
    "    specific_parameters = parameters.keys()\n",
    "    try:\n",
    "        while(True):\n",
    "            print('The weights and biases of these layers have been identified: \\n')\n",
    "            for j in specific_parameters:\n",
    "                print(j)\n",
    "            wanted_parameter = input('Please enter the wanted parameter or enter 0 to exit. Press E to export a specific parameter. \\n')\n",
    "            if wanted_parameter == '0':\n",
    "                break\n",
    "            elif wanted_parameter == 'E' or wanted_parameter == 'e':\n",
    "                wanted_parameter = input('Please enter the parameter to export: \\n')\n",
    "                data = parameters[str(wanted_parameter)].detach()\n",
    "                saving_textfile(data,False)\n",
    "                break\n",
    "            elif wanted_parameter[-4:] == 'bias':\n",
    "                print('There are %i biases in this layer. \\n' % parameters[wanted_parameter].shape)\n",
    "                while(True):\n",
    "                    ith_bias_ith_layer, end = input('Enter the bias range. Enter 0 x to exit: \\n').split()\n",
    "                    if end == 'x':\n",
    "                        break\n",
    "                    else:\n",
    "                        print('\\n')\n",
    "                        print(parameters[wanted_parameter][int(ith_bias_ith_layer):int(end)].detach())\n",
    "                        print('\\n')\n",
    "            else:\n",
    "                print('\\n')\n",
    "                print('There are %d nodes and %d weights from each node. \\n' % (parameters[wanted_parameter].shape[0], parameters[wanted_parameter].shape[1]))\n",
    "                while(True):\n",
    "                    ith_node, ith_weight_ith_node = input('Enter the node number and input weights. Enter 0 x to exit: \\n').split()\n",
    "                    if ith_weight_ith_node == 'x':\n",
    "                        break\n",
    "                    else:\n",
    "                        print('\\n')\n",
    "                        print(parameters[wanted_parameter][int(ith_node)][int(ith_weight_ith_node):int(end)].detach())\n",
    "                        print('\\n')\n",
    "        print('Closed.')\n",
    "    except:\n",
    "        print('You entered an invalid input. Please try again.\\n')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights and biases of these layers have been identified: \n",
      "\n",
      "hidden_layerin.0.weight\n",
      "hidden_layerin.0.bias\n",
      "hidden_layer1.0.weight\n",
      "hidden_layer1.0.bias\n",
      "hidden_layer2.0.weight\n",
      "hidden_layer2.0.bias\n",
      "hidden_layer3.0.weight\n",
      "hidden_layer3.0.bias\n",
      "layer_out.weight\n",
      "layer_out.bias\n",
      "Please enter the wanted parameter or enter 0 to exit. Press E to export a specific parameter. \n",
      "hidden_layerin.0.weight\n",
      "\n",
      "\n",
      "There are 1024 nodes and 784 weights from each node. \n",
      "\n",
      "Enter the node number and input weights. Enter 0 x to exit: \n",
      "0 x\n",
      "The weights and biases of these layers have been identified: \n",
      "\n",
      "hidden_layerin.0.weight\n",
      "hidden_layerin.0.bias\n",
      "hidden_layer1.0.weight\n",
      "hidden_layer1.0.bias\n",
      "hidden_layer2.0.weight\n",
      "hidden_layer2.0.bias\n",
      "hidden_layer3.0.weight\n",
      "hidden_layer3.0.bias\n",
      "layer_out.weight\n",
      "layer_out.bias\n",
      "Please enter the wanted parameter or enter 0 to exit. Press E to export a specific parameter. \n",
      "0\n",
      "Closed.\n"
     ]
    }
   ],
   "source": [
    "weights_biases(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_NN(network,method,directory_network,directory_method):\n",
    "    torch.save(network.state_dict(), directory_network)\n",
    "    torch.save(method.state_dict(), directory_method)\n",
    "    \n",
    "def load_NN(network,method,directory_network,directory_method):\n",
    "    network.load_state_dict(torch.load(directory_network))\n",
    "    method.load_state_dict(torch.load(directory_network))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
